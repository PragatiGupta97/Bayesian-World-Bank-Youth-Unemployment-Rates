---
title: "BDA Project"
author: "Dylan, Francesco, Pragati"
output:
  pdf_document:
    toc: yes
    toc_depth: 1
  html_document:
    toc: yes
    toc_depth: '1'
    df_print: paged
  word_document:
    toc: yes
    toc_depth: '1'
---



```{r setup, include=FALSE}
# This chunk sets echo = TRUE as default, that is print all code.
# knitr::opts_chunk$set can be used to set other notebook generation options, too.
# include=FALSE inside curly brackets makes this block not be included in the pdf
knitr::opts_chunk$set(echo = TRUE)
```


```{r, results='hide',message=FALSE,include=FALSE}
#Loaded packages
# To install aaltobda, see the General information in the assignment.
library(aaltobda)
library(rstan)
library(bayesplot)
library(loo)
library(WVPlots)
library(latticeExtra)
library(sfsmisc)
options(mc.cores = parallel::detectCores(),control = list(max_treedepth = 11))
rstan_options(auto_write = TRUE)
set.seed(123)

```


# 1) Introduction

This report presents how to detect the "Quantitative Response" using Bayesian Inference.Bayesian modeling provides a principled way to quantify uncertainty and incorporate prior knowledge into the model. What is more, **Stan**’s main inference engine, **Hamiltonian Monte Carlo sampling**, is friendly to diagnostics, which means we can verify whether our inference is reliable. Stan is an expressive probabilistic programing language that abstracts the inference and allows users to focus on the modeling. The resulting code is readable and easily extensible, which makes the modeler’s work more transparent and flexible.
For this project **QSAR aquatic toxicity Data Set** has been chosen.


**QSAR toxicity **

```{r}
QSAR <- read.csv(file = 'qsar_aquatic_toxicity.csv')
colnames(QSAR)
```

## Motivation

This dataset was used to develop quantitative regression QSAR models to predict acute aquatic toxicity towards the fish Pimephales promelas (fathead minnow) on a set of 908 chemicals. 
To predict acute aquatic toxicity towards Daphnia Magna, LC50 data, which is the concentration that causes death in 50% of test D. magna over a test duration of 48 hours, was used as model response. 
The model comprised 8 molecular descriptors: TPSA(Tot) (Molecular properties), SAacc (Molecular properties), H-050 (Atom-centred fragments), MLOGP (Molecular properties), RDCHI (Connectivity indices), GATS1p (2D autocorrelations), nN (Constitutional indices), C-040 (Atom-centred fragments).


## The problem



## Modeling idea

In this report, We focus on Bayesian inference with MCMC. Bayesian inference gives us a principled quantification of uncertainty and the ability to incorporate domain knowledge in the form of priors, while MCMC is a reliable and flexible algorithm. In addition, Stan provides diagnostic tools to evaluate both the inference (e.g. accuracy of the MCMC, convergence of chains) and the model (e.g. posterior predictive checks).

## Illustrative figure 

Lets visualizing the density plot of each variable in order to check the range of the  variables in the dataset 
```{r}
par(mfrow=c(3,3))
cols = colnames(QSAR)

for(col in cols)
{ 
plot(density(QSAR[col][,1]), main=col)
  
}

```

# 2) Description of the data and the analysis problem. 

the dataset has been obtained from UCI dataset archives (https://archive.ics.uci.edu/ml/datasets/QSAR+aquatic+toxicity)


|feature number|Feature name|Feature Description|
|---|---|---|
| 1 |TSPA|Tot Molecular properties|
| 2 |SAACC|Molecular properties|
| 3 |H050|Atom-centred fragments|
| 4 |MLOGP|Molecular properties|
| 5 |RDCHI|Connectivity indices|
| 6 |GATS1p|2D autocorrelations|
| 7 |nN|Constitutional indices|
| 8 |C040|Atom-centred fragments|
| 9 |acute aquatic toxicity|

```{r}
PairPlot(QSAR, colnames(QSAR)[1:8], "Pair Plotting of each pair of features", alpha = 0.8,  point_color = "blue")
pairs(QSAR[,1:8], pch = 18,  cex = 0.4, col = "#FC4E07", lower.panel=NULL)
```

```{r}
heatmap(as.matrix(QSAR))
boxplot.default(QSAR, horizontal = TRUE)
```


```{r}
#creating linear model
fullmodel=lm(quantitative_response~TSPA+Saacc+H050+MLOGP+RDCHI+GATS1p+nN+C040, data =QSAR)
summary(fullmodel)
plot(QSAR$quantitative_response,fullmodel$res, ylab="e_bar", xlab="y_bar", main="Residual plot")
abline(0,0)
```

# 3) Description of the two models used

## a) non hierarchical(linear)


## b) hierarchical,


# 4) Informative or weakly informative priors
and justification of their choices.


# 5) Stan code 
## a) non hierarchical(linear)


**Stan Code**
```{r}
code <- file("linear_model_split.stan")
writeLines(readLines(code))
```


## b) hierarchical


```{r}
code_hierarchial <- file("hierarchial.stan")
writeLines(readLines(code_hierarchial))
```


# 6) How to the Stan model was run

that is, what options were used. This is also more clear as combination of textual explanation and the actual code line.

## a) non hierarchical(linear)

```{r}

N_test=20
n=dim(QSAR)[1]
N_train = n-N_test
qr_train=QSAR$quantitative_response[1:N_train]
J=(dim(QSAR)[2]-1)
x_train= QSAR[1:N_train,1:(dim(QSAR)[2]-1)]
#N_test
x_test= QSAR[(N_train+1):n,1:(dim(QSAR)[2]-1)]

qsar_data_check <-list(N_train=N_train,qr_train=qr_train,J=J,x_train=x_train,N_test=N_test, x_test=x_test)

linear_model <-stan(file = 'linear_model_split.stan' , data = qsar_data_check, chains=4, iter=1000)
params=extract(linear_model, permuted=FALSE, inc_warmup=TRUE)

```


## b) hierarchical
```{r}


n=dim(QSAR)[1]

qr=QSAR$quantitative_response
J=(dim(QSAR)[2]-2)
x= QSAR[,1:(dim(QSAR)[2]-2)]
C040=as.integer(QSAR$C040)
nc = length(unique(QSAR$C040))

qsar_data <-list(N=n,qr=qr,J=J,x=x,C040=C040,nc=nc)

hierarchial <-stan(file = 'hierarchial.stan' , data = qsar_data, chains=4, iter=2000)
#print(hierarchial)
```


# 7) Convergence diagnostics 

Here we will discuss 5 types of convergence tests
- Traceplots
- $\hat{R}$
- $n_{eff}$
- Bulk ESS and Tail ESS
- Divergences

## Heirarchial 

### 1) Traceplots

```{r}
traceplot(linear_model, pars=c("alpha","beta"))
```

### 2) $\hat{R}$

From printed output we can see that $\hat{R}$ < 1.01 for all the parameters

### 3) $n_{eff}$

```{r}
neff=summary(linear_model)$summary[,'n_eff']
val=neff/1000 
#print(val)
which(val < 0.01)
```

samples/ total iterations > 0.01, this means samples are not biased and true effect of sample size is not overestimated.

### 4) Bulk ESS and Tail ESS

BUlk ESS and tail ess over 100 for all the parameters

### 5) Divergences

```{r}
#pairs(model_simple,pars=c("a","b","c","d","e","f","g","h","i"))
get_num_divergent(linear_model)
```

No divergences in the pairplot


## Heirarchial 

```{r}

#mcmc_trace(as.array(model_simple), pars = c("a","b","c","d","e","f","g","h","i"), facet_args = list(nrow = 3))
traceplot(hierarchial, pars=c("a","b","c","d","e","f","g","h"))
```

### 2) $\hat{R}$

From printed output we can see that $\hat{R}$ < 1.06 for all the parameters

### 3) $n_{eff}$

```{r}
neff=summary(hierarchial)$summary[,'n_eff']
val=neff/2000 
#print(val)
which(val < 0.01)
```

samples/ total iterations > 0.01, this means samples are not biased and true effect of sample size is not overestimated.

### 4) Bulk ESS and Tail ESS

BUlk ESS and tail ess over 100 for all the parameters

### 5) Divergences

```{r}
#pairs(model_simple,pars=c("a","b","c","d","e","f","g","h","i"))
```

```{r}
get_num_divergent(hierarchial)
```

Initially the divergences were 552, 
but after setting the adapt_delta=0.95, the divergences were reduced to 408.
So we eavaluated the hierarchial model was not satisafactory.



# 8) Posterior predictive checks

## Non-Heirarchial 
and what was done to improve the model.
```{r}
# instead of log, use rng
plot(density(QSAR$quantitative_response),main="Posterior predictive check for simple model")
params<-extract(linear_model)
for (ind in 1980:2000)
{
  lines(density(params$gen_lik[ind,]), col='red');
}

```
##  Heirarchial 
and what was done to improve the model.
```{r}
# instead of log, use rng
plot(density(QSAR$quantitative_response),main="Posterior predictive check for simple model")
params<-extract(hierarchial)
for (ind in 3980:4000)
{
  lines(density(params$gen_lik[ind,]), col='red');
}

```

# 9) Model comparison 
(e.g. with LOO-CV).



## Non Heirarchial 
```{r}
loo_model_linear <- loo(extract_log_lik(linear_model))
print(loo_model_linear)
plot(loo_model_linear, main = "PSIS Diagonostic for simple Model")
```
## Hierarchial 

```{r}
loo_model_hierarchial <- loo(extract_log_lik(hierarchial))
loo_model_hierarchial
plot(loo_model_hierarchial, main = "PSIS Diagonostic for Heirarchial Model")
```



# 10) Predictive performance assessment 

if applicable (e.g. classification accuracy) and evaluation of practical usefulness of the accuracy.


```{r}
new_params= extract(linear_model)
pred_scores = colMeans(new_params$qr_test)
pred_error = sapply(1:N_test, function(x) sd(new_params$qr_test[,x]))
true_scores = QSAR$quantitative_response[(N_train+1):n]
plot(true_scores,pred_scores,xlim=range(1:10), ylim=range(1:10))
abline(a=0,b=1,lty="dashed")
arrows(true_scores,pred_scores+pred_error,true_scores,pred_scores-pred_error, length =0.05, angle = 90, code =3)

```
# 11) Sensitivity analysis 

with respect to prior choices (i.e. checking whether the result changes a lot if prior is changed)

2 types of priors


# 12) Discussion of issues and potential improvements.

# 13) Conclusion 

what was learned from the data analysis.

# 14) Self-reflection of what the group learned while making the project.


